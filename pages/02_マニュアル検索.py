import streamlit as st
from openai import OpenAI
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

st.title("ğŸš ç‰›ã‚ã—å‡¦ã€ã‚ã˜ã‚ã„äº­ã€æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«æ¤œç´¢")
st.write("æ–°äººã•ã‚“å‘ã‘ï¼šãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‹ã‚‰æ¤œç´¢ã—ã¦å›ç­”ã—ã¾ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«æ³¨æ„æ›¸ã
with st.sidebar:
    st.write("â€»æ¶ç©ºã®ç‰›ã‚ã—å±‹ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã§ã™")

# APIã‚­ãƒ¼ã®è¨­å®š
try:
    # LangChainã§ã‚‚APIã‚­ãƒ¼ãŒå¿…è¦ãªã®ã§ã€ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦è¨­å®š
    import os
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception as e:
    st.error("APIã‚­ãƒ¼ã®è¨­å®šãŒå¿…è¦ã§ã™ã€‚")
    st.stop()

# ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã€Œæ¤œç´¢ã§ãã‚‹å½¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã€ã«ã™ã‚‹
# ä¸€åº¦ä½œã£ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ã„å›ã™ã®ã§æ—©ããªã‚‹ï¼
@st.cache_resource
def create_vector_store():
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    loader = TextLoader("manual.txt", encoding="utf-8")
    documents = loader.load()

    # é•·ã„æ–‡ç« ã‚’ã€Œãƒãƒ£ãƒ³ã‚¯ï¼ˆå¡Šï¼‰ã€ã«åˆ†å‰²ã™ã‚‹
    text_splitter = CharacterTextSplitter(
        separator="\n",    # æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã§åŒºåˆ‡ã‚‹
        chunk_size=500,    # 500æ–‡å­—ã”ã¨ã®å¡Šã«ã™ã‚‹
        chunk_overlap=0    # é‡è¤‡ã¯ãªã—
    )
    chunks = text_splitter.split_documents(documents)

    # æ–‡ç« ã‚’ã€Œæ•°å€¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã€ã«å¤‰æ›ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹(FAISS)ã«å…¥ã‚Œã‚‹
    embeddings = OpenAIEmbeddings()
    vector_store = FAISS.from_documents(chunks, embeddings)
    
    return vector_store

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆï¼ˆåˆå›ã®ã¿å®Ÿè¡Œã•ã‚Œã€2å›ç›®ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒä½¿ã‚ã‚Œã‚‹ï¼‰
try:
    vector_store = create_vector_store()
    st.success("ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã®èª­ã¿è¾¼ã¿å®Œäº†ï¼è³ªå•ã©ã†ãï¼")
except Exception as e:
    st.error(f"ãƒãƒ‹ãƒ¥ã‚¢ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å—ã‘ä»˜ã‘ã‚‹
prompt = st.chat_input("ä¾‹ï¼šæ‰‹æ´—ã„ã®æ‰‹é †ã¯ï¼Ÿ / ç…®è¾¼ã¿æ™‚é–“ã¯ï¼Ÿ")

if prompt:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¡¨ç¤º
    with st.chat_message("user"):
        st.write(prompt)

    # ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‹ã‚‰ã€Œé–¢ä¿‚ã‚ã‚Šãã†ãªéƒ¨åˆ†ã€ã‚’æ¤œç´¢ã™ã‚‹
    with st.chat_message("assistant"):
        with st.spinner("ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’æ¤œç´¢ä¸­..."):
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã€è³ªå•ã«è¿‘ã„æ–‡ç« ã‚’3ã¤æ¢ã—ã¦ãã‚‹
            docs = vector_store.similarity_search(prompt, k=3)
            
            # æ¤œç´¢ã§è¦‹ã¤ã‹ã£ãŸãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã®æ–‡ç« ã‚’åˆä½“ã•ã›ã‚‹
            context = "\n\n".join([doc.page_content for doc in docs])

            #  AIã«å›ç­”ã‚’ä½œã‚‰ã›ã‚‹
            # ã€Œæ¤œç´¢çµæœ(context)ã€ã¨ã€Œè³ªå•(prompt)ã€ã‚’ã‚»ãƒƒãƒˆã«ã—ã¦æŠ•ã’ã‚‹
            system_prompt = f"""
            ã‚ãªãŸã¯ã€ç‰›ã‚ã—å‡¦ ã‚ã˜ã‚ã„äº­ã€ã®ãƒ™ãƒ†ãƒ©ãƒ³åº—é•·ã§ã™ã€‚
            ä»¥ä¸‹ã®ã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã®æŠœç²‹ã€‘ã«åŸºã¥ã„ã¦ã€æ–°äººã‚¹ã‚¿ãƒƒãƒ•ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
            
            # ãƒ«ãƒ¼ãƒ«
            - ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«æ›¸ã„ã¦ã‚ã‚‹ã“ã¨ã ã‘ã‚’ç­”ãˆã¦ãã ã•ã„ã€‚
            - ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«ãªã„ã“ã¨ã¯ã€Œãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«ã¯è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚
            - å„ªã—ãã€ã‚ã‹ã‚Šã‚„ã™ãæ•™ãˆã¦ãã ã•ã„ã€‚

            # ã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã®æŠœç²‹ã€‘
            {context}
            """

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ]
            )
            
            ai_answer = response.choices[0].message.content
            st.write(ai_answer)
            
            # ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ã©ã®éƒ¨åˆ†ã‚’å‚ç…§ã—ãŸã‹è¡¨ç¤ºã™ã‚‹
            with st.expander("å‚ç…§ã—ãŸãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç®‡æ‰€"):
                st.write(context)